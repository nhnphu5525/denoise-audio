{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45613a84",
   "metadata": {},
   "source": [
    "Tiền xử lý trước khi đưa vào UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c1919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121\n",
      "✅ GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import kagglehub\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"❌ CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13621cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to C:\\Users\\quany\\.cache\\kagglehub\\datasets\\kynthesis\\vivos-vietnamese-speech-corpus-for-asr\\1.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.37G/1.37G [01:06<00:00, 22.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to C:\\Users\\quany\\.cache\\kagglehub\\datasets\\chrisfilo\\demand\\1.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.87G/6.87G [05:25<00:00, 22.6MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIVOS path: C:\\Users\\quany\\.cache\\kagglehub\\datasets\\kynthesis\\vivos-vietnamese-speech-corpus-for-asr\\versions\\1\n",
      "DEMAND path: C:\\Users\\quany\\.cache\\kagglehub\\datasets\\chrisfilo\\demand\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "vivos_path = kagglehub.dataset_download(\n",
    "    \"kynthesis/vivos-vietnamese-speech-corpus-for-asr\"\n",
    ")\n",
    "\n",
    "demand_path = kagglehub.dataset_download(\n",
    "    \"chrisfilo/demand\"\n",
    ")\n",
    "\n",
    "print(\"VIVOS path:\", vivos_path)\n",
    "print(\"DEMAND path:\", demand_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7904faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech files: 12420\n",
      "Noise files : 560\n"
     ]
    }
   ],
   "source": [
    "def collect_wavs(root):\n",
    "    return [\n",
    "        os.path.join(r, f)\n",
    "        for r, _, files in os.walk(root)\n",
    "        for f in files if f.lower().endswith(\".wav\")\n",
    "    ]\n",
    "\n",
    "speech_files = collect_wavs(vivos_path)\n",
    "noise_files  = collect_wavs(demand_path)\n",
    "\n",
    "print(\"Speech files:\", len(speech_files))\n",
    "print(\"Noise files :\", len(noise_files))\n",
    "\n",
    "assert len(speech_files) > 0\n",
    "assert len(noise_files) > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcf423c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_SEC = 0.3\n",
    "SNR_MIN, SNR_MAX = 0, 20\n",
    "\n",
    "\n",
    "def pad_to_length(x, target_len):\n",
    "    if len(x) < target_len:\n",
    "        x = np.pad(x, (0, target_len - len(x)))\n",
    "    return x\n",
    "\n",
    "\n",
    "def match_length(x, target_len):\n",
    "    if len(x) < target_len:\n",
    "        x = np.tile(x, int(np.ceil(target_len / len(x))))\n",
    "    return x[:target_len]\n",
    "\n",
    "\n",
    "def mix_with_snr(clean, noise, snr_db):\n",
    "    clean_power = np.mean(clean ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "\n",
    "    noise = noise * np.sqrt(\n",
    "        clean_power / (noise_power * 10 ** (snr_db / 10))\n",
    "    )\n",
    "    return clean + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "930ee639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveform_to_spectrogram(\n",
    "    y,\n",
    "    sr,\n",
    "    n_fft=512,\n",
    "    hop_length=256,\n",
    "    target_shape=(256, 256)\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert waveform -> log-magnitude spectrogram\n",
    "    Output shape: (256, 256, 1)\n",
    "    \"\"\"\n",
    "    stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    mag = np.abs(stft)\n",
    "\n",
    "    log_mag = np.log1p(mag)\n",
    "\n",
    "    # normalize to [0, 1]\n",
    "    log_mag = (log_mag - log_mag.min()) / (\n",
    "        log_mag.max() - log_mag.min() + 1e-8\n",
    "    )\n",
    "\n",
    "    spec = np.zeros(target_shape, dtype=np.float32)\n",
    "    h = min(log_mag.shape[0], target_shape[0])\n",
    "    w = min(log_mag.shape[1], target_shape[1])\n",
    "    spec[:h, :w] = log_mag[:h, :w]\n",
    "\n",
    "    return spec[..., np.newaxis]  # (256,256,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac24f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_sample():\n",
    "    \"\"\"\n",
    "    Generate ONE training sample on-the-fly\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    noisy_spec : np.ndarray (256,256,1)\n",
    "        Input for U-Net\n",
    "    clean_spec : np.ndarray (256,256,1)\n",
    "        Target for U-Net\n",
    "    meta : dict\n",
    "        Metadata for debugging / logging\n",
    "    \"\"\"\n",
    "\n",
    "    # 1️⃣ Random speech file\n",
    "    sp_path = random.choice(speech_files)\n",
    "    speech, sr = librosa.load(sp_path, sr=None, mono=True)\n",
    "\n",
    "    # 2️⃣ Random 0.3s segment\n",
    "    seg_len = int(sr * SEGMENT_SEC)\n",
    "    max_start = max(0, len(speech) - seg_len)\n",
    "    start = random.randint(0, max_start)\n",
    "\n",
    "    clean = speech[start:start + seg_len]\n",
    "    clean = pad_to_length(clean, seg_len)\n",
    "\n",
    "    # 3️⃣ Random noise file\n",
    "    noise_path = random.choice(noise_files)\n",
    "    noise, _ = librosa.load(noise_path, sr=sr, mono=True)\n",
    "    noise = match_length(noise, len(clean))\n",
    "\n",
    "    # 4️⃣ Random SNR\n",
    "    snr_db = random.uniform(SNR_MIN, SNR_MAX)\n",
    "    noisy = mix_with_snr(clean, noise, snr_db)\n",
    "\n",
    "    # 5️⃣ Convert to spectrogram (model input)\n",
    "    clean_spec = waveform_to_spectrogram(clean, sr)\n",
    "    noisy_spec = waveform_to_spectrogram(noisy, sr)\n",
    "\n",
    "    meta = {\n",
    "        \"speech_path\": sp_path,\n",
    "        \"noise_path\": noise_path,\n",
    "        \"sample_rate\": sr,\n",
    "        \"segment_samples\": seg_len,\n",
    "        \"segment_seconds\": SEGMENT_SEC,\n",
    "        \"snr_db\": snr_db,\n",
    "        \"waveform_rms_clean\": float(np.sqrt(np.mean(clean ** 2))),\n",
    "        \"waveform_rms_noisy\": float(np.sqrt(np.mean(noisy ** 2))),\n",
    "    }\n",
    "\n",
    "    return noisy_spec, clean_spec, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6721f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAMPLE METADATA ===\n",
      "speech_path: C:\\Users\\quany\\.cache\\kagglehub\\datasets\\kynthesis\\vivos-vietnamese-speech-corpus-for-asr\\versions\\1\\vivos\\train\\waves\\VIVOSSPK01\\VIVOSSPK01_R122.wav\n",
      "noise_path: C:\\Users\\quany\\.cache\\kagglehub\\datasets\\chrisfilo\\demand\\versions\\1\\OHALLWAY_16k\\OHALLWAY\\ch06.wav\n",
      "sample_rate: 16000\n",
      "segment_samples: 4800\n",
      "segment_seconds: 0.3\n",
      "snr_db: 0.36762275060037153\n",
      "waveform_rms_clean: 0.050982117652893066\n",
      "waveform_rms_noisy: 0.07055313885211945\n",
      "\n",
      "=== TENSOR SHAPES ===\n",
      "Noisy spec shape : (256, 256, 1)\n",
      "Clean spec shape : (256, 256, 1)\n",
      "\n",
      "=== VALUE RANGE ===\n",
      "Noisy  min/max: 0.0 1.0\n",
      "Clean  min/max: 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "noisy_spec, clean_spec, meta = generate_one_sample()\n",
    "\n",
    "print(\"=== SAMPLE METADATA ===\")\n",
    "for k, v in meta.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\n=== TENSOR SHAPES ===\")\n",
    "print(\"Noisy spec shape :\", noisy_spec.shape)\n",
    "print(\"Clean spec shape :\", clean_spec.shape)\n",
    "\n",
    "print(\"\\n=== VALUE RANGE ===\")\n",
    "print(\"Noisy  min/max:\", noisy_spec.min(), noisy_spec.max())\n",
    "print(\"Clean  min/max:\", clean_spec.min(), clean_spec.max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
